{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Surfrider Video processing notebook\n",
    "\n",
    "This notebook aims at producing semi-synthetic dataset for training models\n",
    "\n",
    "Make sure you have ffmpeg on your computer, for instance with:\n",
    "\n",
    "`sudo apt-get install ffmpeg`\n",
    "\n",
    "Then install the python package:\n",
    "\n",
    "`pip install ffmpeg-python`\n",
    "\n",
    "## Spliting a video into frames\n",
    "\n",
    "(code from the mot repository)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ffmpeg\n",
    "import os\n",
    "%matplotlib inline\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_video(input_path, output_folder, fps=1.5, resolution=(1024, 768)):\n",
    "    \"\"\"Splits a video into frames\n",
    "\n",
    "    Arguments:\n",
    "\n",
    "    - *input_path*: string of video full path\n",
    "    - *output_folder*: folder to store images\n",
    "    - *fps*: float for number of frames per second\n",
    "    - *resolution*: integer tuple for resolution\n",
    "\n",
    "    \"\"\"\n",
    "    if not os.path.isdir(output_folder):\n",
    "        os.mkdir(output_folder)\n",
    "    (\n",
    "        ffmpeg.input(input_path).filter(\n",
    "            \"scale\", width=\"{}\".format(resolution[0]), height=\"{}\".format(resolution[1])\n",
    "        ).filter(\"fps\", fps=fps, round=\"up\").trim(\n",
    "            start_frame=0\n",
    "        ).output(os.path.join(output_folder, \"frame_%4d.jpeg\"), format=\"image2\",\n",
    "                 vcodec=\"mjpeg\").run()\n",
    "    )\n",
    "\n",
    "\n",
    "def read_folder(input_path):\n",
    "    # for now, read directly from images in folder ; later from json outputs\n",
    "    return [os.path.join(input_path, file) for file in sorted(os.listdir(input_path))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = 'real-dataset-1/b3e4d8d1-cdbc-4539-92f2-7845df756ee4_48.8068478_1.3645054.mp4'\n",
    "output_folder=os.path.join(\".\",\"real-dataset-1-images\")\n",
    "\n",
    "split_video(input_path=input_path,\n",
    "            output_folder=output_folder,\n",
    "            fps=12,\n",
    "            resolution=(960, 540))\n",
    "\n",
    "# Read the paths\n",
    "video_images =read_folder(output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get annotations and images from TACO\n",
    "\n",
    "To do so, clone the TACO repository and download the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '../TACO/data'\n",
    "anns_file_path = dataset_path + '/' + 'annotations.json'\n",
    "\n",
    "# Read annotations\n",
    "with open(anns_file_path, 'r') as f:\n",
    "    dataset = json.loads(f.read())\n",
    "\n",
    "categories = dataset['categories']\n",
    "anns = dataset['annotations']\n",
    "imgs = dataset['images']\n",
    "nr_cats = len(categories)\n",
    "nr_annotations = len(anns)\n",
    "nr_images = len(imgs)\n",
    "\n",
    "# Load categories and super categories\n",
    "cat_names = []\n",
    "super_cat_names = []\n",
    "super_cat_ids = {}\n",
    "super_cat_last_name = ''\n",
    "nr_super_cats = 0\n",
    "for cat_it in categories:\n",
    "    cat_names.append(cat_it['name'])\n",
    "    super_cat_name = cat_it['supercategory']\n",
    "    # Adding new supercat\n",
    "    if super_cat_name != super_cat_last_name:\n",
    "        super_cat_names.append(super_cat_name)\n",
    "        super_cat_ids[super_cat_name] = nr_super_cats\n",
    "        super_cat_last_name = super_cat_name\n",
    "        nr_super_cats += 1\n",
    "\n",
    "print('Number of super categories:', nr_super_cats)\n",
    "print('Number of categories:', nr_cats)\n",
    "print('Number of annotations:', nr_annotations)\n",
    "print('Number of images:', nr_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map to our categories\n",
    "\n",
    "ids_plastic = list(range(36,42))\n",
    "ids_other = [10,11,12,43,44,45,46,47,51,53]\n",
    "ids_bottle = [4,5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crop an image with points\n",
    "\n",
    "Points should be a numpy array of shape (nb_points, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_img(img, pts):\n",
    "    print(pts.shape)\n",
    "    # get bounding box\n",
    "    rect = cv2.boundingRect(pts)\n",
    "    x,y,w,h = rect\n",
    "    croped = img[y:y+h, x:x+w].copy()\n",
    "\n",
    "    ## (2) make mask\n",
    "    pts = pts - pts.min(axis=0)\n",
    "\n",
    "    mask = np.zeros(croped.shape[:2], np.uint8)\n",
    "    print(mask.shape)\n",
    "    cv2.drawContours(mask, [pts], -1, (255, 255, 255), -1, cv2.LINE_AA)\n",
    "    \n",
    "    ## (3) do bit-op\n",
    "    dst = cv2.bitwise_and(croped, croped, mask=mask)\n",
    "\n",
    "    ## (4) add the alpha channel\n",
    "    rgba = cv2.cvtColor(dst, cv2.COLOR_RGB2RGBA)\n",
    "    rgba[:, :, 3] = mask\n",
    "    return rgba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get a random annotation & image from TACO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_label_to_ann_ids = {\"bottle\":[], \"fragment\":[], \"other\":[]}\n",
    "for idx, ann in enumerate(anns):\n",
    "    if ann[\"category_id\"] in ids_bottle:\n",
    "        dict_label_to_ann_ids[\"bottle\"] += [idx]\n",
    "    elif ann[\"category_id\"] in ids_plastic:\n",
    "        dict_label_to_ann_ids[\"fragment\"] += [idx]\n",
    "    elif ann[\"category_id\"] in ids_other:\n",
    "        dict_label_to_ann_ids[\"other\"] += [idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import random\n",
    "\n",
    "def get_random_trash(label):\n",
    "    list_idx = dict_label_to_ann_ids[label]\n",
    "    idx = random.choice(list_idx)\n",
    "    ann = anns[idx]\n",
    "    img_id = ann['image_id']\n",
    "    img_path = os.path.join(dataset_path, imgs[img_id]['file_name'])\n",
    "\n",
    "    img = cv2.imread(img_path)\n",
    "    #idx_seg = random.choice(len(ann[\"segmentation\"]))\n",
    "    seg = random.choice(ann['segmentation'])\n",
    "    pts = np.array(list(zip(seg[::2], seg[1::2]))).astype(int)\n",
    "    return crop_img(img, pts)\n",
    "\n",
    "trash_img = get_random_trash(label=\"bottle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(trash_img);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overlay a transparent image onto the background image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay_transparent(background_img, img_to_overlay_t, x, y, overlay_size=None):\n",
    "\n",
    "    bg_img = background_img.copy()\n",
    "    background_height, background_width, _ = bg_img.shape\n",
    "    \n",
    "    if overlay_size is not None:\n",
    "        img_to_overlay_t = cv2.resize(img_to_overlay_t.copy(), overlay_size)\n",
    "\n",
    "    # Extract the alpha mask of the RGBA image, convert to RGB \n",
    "    b,g,r,a = cv2.split(img_to_overlay_t)\n",
    "    overlay_color = cv2.merge((b,g,r))\n",
    "    \n",
    "    # Apply some simple filtering to remove edge noise\n",
    "    mask = cv2.medianBlur(a,5)\n",
    "\n",
    "    # Border conditions\n",
    "    h, w, _ = overlay_color.shape\n",
    "    if x < 0:\n",
    "        w = w + x\n",
    "        mask = mask[:, -x:]\n",
    "        overlay_color = overlay_color[:, -x:]\n",
    "        x = 0\n",
    "    \n",
    "    if y < 0:\n",
    "        h = h + y\n",
    "        mask = mask[-y:, :]\n",
    "        overlay_color = overlay_color[-y:, :]\n",
    "        y = 0\n",
    "    \n",
    "    if x + w > background_width:\n",
    "        w = background_width - x\n",
    "        mask = mask[:, :w]\n",
    "        overlay_color = overlay_color[:, :w]\n",
    "\n",
    "    if y + h > background_height:\n",
    "        h = background_height - y\n",
    "        mask = mask[:h, :]\n",
    "        overlay_color = overlay_color[:h, :]\n",
    "    \n",
    "    roi = bg_img[y:y+h, x:x+w]\n",
    "\n",
    "    # Black-out the area behind the overlay in our original ROI\n",
    "    img1_bg = cv2.bitwise_and(roi.copy(),roi.copy(),mask = cv2.bitwise_not(mask))\n",
    "\n",
    "    # Mask out the overlay from the logo image.\n",
    "    img2_fg = cv2.bitwise_and(overlay_color,overlay_color,mask = mask)\n",
    "\n",
    "    # Update the original image with our new ROI\n",
    "    bg_img[y:y+h, x:x+w] = cv2.add(img1_bg, img2_fg)\n",
    "\n",
    "    return bg_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = cv2.resize(outp, (100,int(100*outp.shape[0]/outp.shape[1])))\n",
    "\n",
    "video_image = cv2.imread(video_images[0])\n",
    "rows,cols,channels = output.shape\n",
    "\n",
    "output_image = overlay_transparent(video_image, output, -50, 200)\n",
    "output_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_rgb = cv2.cvtColor(output_image, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(im_rgb);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This class represents an object and its location within the video\n",
    "# Todo add blending, data augmentation, etc...\n",
    "\n",
    "class OverlayTrash():\n",
    "    def __init__(self, trash_image, init_loc, final_loc, \n",
    "              size, init_frame, final_frame):\n",
    "        \n",
    "        self.trash_image = trash_image\n",
    "        self.init_loc, self.final_loc = init_loc, final_loc\n",
    "        self.init_frame, self.final_frame = init_frame, final_frame\n",
    "        self.span_x = (final_loc[0] - init_loc[0])\n",
    "        self.span_y = (final_loc[1] - init_loc[1])\n",
    "        self.length = final_frame - init_frame\n",
    "        self.reshape_size = (size, int(size*trash_image.shape[0]/trash_image.shape[1]))\n",
    "        self.size = size\n",
    "        \n",
    "    def get_position(self, frame_idx):\n",
    "        alpha = (frame_idx - self.init_frame) / self.length\n",
    "        x = int(self.init_loc[0] + self.span_x * alpha)\n",
    "        y = int(self.init_loc[1] + self.span_y * alpha)\n",
    "        return (x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_trash(video_images, trash_list, output_folder):\n",
    "    for frame_idx, frame in enumerate(video_images):\n",
    "        video_image = cv2.imread(frame)\n",
    "        filename = os.path.basename(frame)\n",
    "        for trash in trash_list:\n",
    "            if frame_idx >= trash.init_frame and frame_idx <= trash.final_frame:\n",
    "                x,y = trash.get_position(frame_idx)\n",
    "                video_image = overlay_transparent(video_image, trash.trash_image, \n",
    "                                                  x, y, trash.reshape_size)\n",
    "            \n",
    "        cv2.imwrite(os.path.join(output_folder,filename), video_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder2 = os.path.join(\".\",\"real-dataset-1-images-out\")\n",
    "if not os.path.isdir(output_folder2):\n",
    "    os.mkdir(output_folder2)\n",
    "    \n",
    "trash = OverlayTrash(output,\n",
    "          (950, 200),\n",
    "          (-20, 400),\n",
    "          70,\n",
    "          20, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_trash(video_images[:100],\n",
    "          [trash],\n",
    "          output_folder2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.basename(video_images[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Todo: save synthetic labels \n",
    "\n",
    "- Trash type\n",
    "- which frames they appear in (first, middle, last)\n",
    "- positions in each frame ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [{\"class\":\"bottle\", \"times\":[624,644,653]},]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (optional) Generate a new video from output frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    ffmpeg\n",
    "    .input(os.path.join(output_folder2, \"*.jpeg\"), pattern_type='glob', framerate=12)\n",
    "    .output('1-added_trash.mp4')\n",
    "    .run()\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
